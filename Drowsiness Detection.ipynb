{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b7ea59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593fcde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= keras.models.load_model('Drowsy1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a5d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_coordinates(landmarks) :\n",
    "    '''This function takes the face landmarks of one person in one frame and  \n",
    "    returns the (x,y) coordinates of face in 2D and (x,y,z) coordinates in 3D.\n",
    "    '''\n",
    "    \n",
    "    face_3d=[]\n",
    "    face_2d=[]\n",
    "    for idx, landmark in enumerate(landmarks):\n",
    "        ''' idx runs over all the 468 face landmark points '''\n",
    "        \n",
    "        x,y= int(landmark.x * width), int(landmark.y * height)\n",
    "        face_2d.append([x,y])\n",
    "        face_3d.append([x,y,landmark.z])\n",
    "    face_2d = np.array(face_2d, dtype=np.float64)\n",
    "    face_3d = np.array(face_3d, dtype=np.float64)\n",
    "    return face_2d, face_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b74b07c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_angles(face_2d, face_3d):\n",
    "    ''' This function takes the 2D and 3D face landmarks coordinates and\n",
    "         returns the x, y, z angles of the head with respect to camera.'''\n",
    "    \n",
    "    focal_length = 2* width\n",
    "    cam_matrix = np.array([[focal_length, 0, height/2], [0,focal_length, width/2], [0,0,1]])\n",
    "    dist_matrix = np.zeros((4,1), dtype=np.float64) # distortion parameters\n",
    "\n",
    "    success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix) # Rotation and translation\n",
    "\n",
    "    rot_matrix, jacobian= cv2.Rodrigues(rot_vec)\n",
    "    angles, mtxr, mtxq, qx,qy,qz = cv2.RQDecomp3x3(rot_matrix)\n",
    "    x= angles[0] * 360\n",
    "    y= angles[1] * 360\n",
    "    z= angles[2] * 360\n",
    "    return (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "124b52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drowsy_detector(image):\n",
    "    image = cv2.resize(image1, (224, 224))\n",
    "    image = image/255.\n",
    "    image = np.reshape(image, (1,224,224,3))\n",
    "    pred = np.argmax(model.predict(image))     \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bbc3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def head_direction(x,y):\n",
    "    ''' This function takes the x and y angles\n",
    "    and gives the direction of head turn.'''\n",
    "    \n",
    "    if y < 2:\n",
    "        text = 'Looking Left'\n",
    "    elif y >14:\n",
    "        text= 'Looking Right'\n",
    "    elif x < -5:\n",
    "        text = 'Looking Down'\n",
    "    elif x > 5:\n",
    "        text = 'Looking Up'\n",
    "    else: text = 'Looking Forward'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21057678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.8)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence =0.5)\n",
    "counter_head =1\n",
    "counter_alert=1\n",
    "from pygame import mixer\n",
    "mixer.init()\n",
    "voice_head = mixer.Sound('forward.wav')\n",
    "voice_alert= mixer.Sound('alert.wav')\n",
    "\n",
    "while True:\n",
    "    still_reading, frame = cap.read()\n",
    "    if not still_reading:\n",
    "        break\n",
    "    else:\n",
    "        image1 = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image1)\n",
    "        height, width, channels = image1.shape\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                face_2d, face_3d = face_coordinates(face_landmarks.landmark)\n",
    "                x, y, z = head_angles(face_2d, face_3d)\n",
    "                direction = head_direction(x,y)\n",
    "                if direction != 'Looking Forward':\n",
    "                    counter_head+=1\n",
    "                cv2.putText(image1, direction, (20,150), cv2.FONT_HERSHEY_COMPLEX, 2, (0,255,0), 2)\n",
    "                \n",
    "            prediction = drowsy_detector(image1)\n",
    "            if (prediction==0 or prediction ==3):\n",
    "                message='The person is drowsy'\n",
    "                counter_alert +=1\n",
    "                cv2.putText(image1, message, (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(255,0,0), 2)\n",
    "            else:\n",
    "                message = 'Not Drowsy'\n",
    "                cv2.putText(image1, message, (50,50),cv2.FONT_HERSHEY_SIMPLEX, 1,(0,255,0), 2)\n",
    "            \n",
    "        else:\n",
    "            print('No face detected')\n",
    "            continue\n",
    "        if counter_head % 5 ==0:\n",
    "            voice_head.play()\n",
    "        if counter_alert % 5==0:\n",
    "            voice_alert.play()\n",
    "\n",
    "    image = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)    \n",
    "    cv2.imshow('Drowsiness Detection', image)\n",
    "    if cv2.waitKey(1000) & 0xFF ==ord('k'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a5ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Closed': 0, 'Open': 1, 'no_yawn': 2, 'yawn': 3}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
